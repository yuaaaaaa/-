{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_v1.py:2070: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from net.mtcnn import mtcnn\n",
    "import utils.utils as utils\n",
    "from net.inception import InceptionResNetV1\n",
    "\n",
    "class face_rec():\n",
    "    def __init__(self):\n",
    "        # 创建mtcnn对象\n",
    "        # 检测图片中的人脸\n",
    "        self.mtcnn_model = mtcnn()\n",
    "        # 门限函数\n",
    "        self.threshold = [0.5,0.8,0.9]\n",
    "\n",
    "        # 载入facenet\n",
    "        # 将检测到的人脸转化为128维的向量\n",
    "        self.facenet_model = InceptionResNetV1()\n",
    "        # model.summary()\n",
    "        model_path = './model_data/facenet_keras.h5'\n",
    "        self.facenet_model.load_weights(model_path)\n",
    "\n",
    "        #-----------------------------------------------#\n",
    "        #   对数据库中的人脸进行编码\n",
    "        #   known_face_encodings中存储的是编码后的人脸\n",
    "        #   known_face_names为人脸的名字\n",
    "        #-----------------------------------------------#\n",
    "        face_list = os.listdir(\"face_dataset\")\n",
    "\n",
    "        self.known_face_encodings=[]\n",
    "\n",
    "        self.known_face_names=[]\n",
    "\n",
    "        for face in face_list:\n",
    "            if face == '.DS_Store':\n",
    "                continue\n",
    "            name = face.split(\".\")[0]\n",
    "\n",
    "            img = cv2.imread(\"./face_dataset/\"+face)\n",
    "            img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # 检测人脸\n",
    "            rectangles = self.mtcnn_model.detectFace(img, self.threshold)\n",
    "\n",
    "            # 转化成正方形\n",
    "            rectangles = utils.rect2square(np.array(rectangles))\n",
    "            # facenet要传入一个160x160的图片\n",
    "            rectangle = rectangles[0]\n",
    "            # 记下他们的landmark\n",
    "            landmark = (np.reshape(rectangle[5:15],(5,2)) - np.array([int(rectangle[0]),int(rectangle[1])]))/(rectangle[3]-rectangle[1])*160\n",
    "\n",
    "            crop_img = img[int(rectangle[1]):int(rectangle[3]), int(rectangle[0]):int(rectangle[2])]\n",
    "            crop_img = cv2.resize(crop_img,(160,160))\n",
    "\n",
    "            new_img,_ = utils.Alignment_1(crop_img,landmark)\n",
    "\n",
    "            new_img = np.expand_dims(new_img,0)\n",
    "            # 将检测到的人脸传入到facenet的模型中，实现128维特征向量的提取\n",
    "            face_encoding = utils.calc_128_vec(self.facenet_model,new_img)\n",
    "\n",
    "            self.known_face_encodings.append(face_encoding)\n",
    "            self.known_face_names.append(name)\n",
    "\n",
    "    def recognize(self,draw):\n",
    "        #-----------------------------------------------#\n",
    "        #   人脸识别\n",
    "        #   先定位，再进行数据库匹配\n",
    "        #-----------------------------------------------#\n",
    "        height,width,_ = np.shape(draw)\n",
    "        draw_rgb = cv2.cvtColor(draw,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 检测人脸\n",
    "        rectangles = self.mtcnn_model.detectFace(draw_rgb, self.threshold)\n",
    "\n",
    "        if len(rectangles)==0:\n",
    "            return\n",
    "\n",
    "        # 转化成正方形\n",
    "        rectangles = utils.rect2square(np.array(rectangles,dtype=np.int32))\n",
    "        rectangles[:,0] = np.clip(rectangles[:,0],0,width)\n",
    "        rectangles[:,1] = np.clip(rectangles[:,1],0,height)\n",
    "        rectangles[:,2] = np.clip(rectangles[:,2],0,width)\n",
    "        rectangles[:,3] = np.clip(rectangles[:,3],0,height)\n",
    "        #-----------------------------------------------#\n",
    "        #   对检测到的人脸进行编码\n",
    "        #-----------------------------------------------#\n",
    "        face_encodings = []\n",
    "        for rectangle in rectangles:\n",
    "            landmark = (np.reshape(rectangle[5:15],(5,2)) - np.array([int(rectangle[0]),int(rectangle[1])]))/(rectangle[3]-rectangle[1])*160\n",
    "\n",
    "            crop_img = draw_rgb[int(rectangle[1]):int(rectangle[3]), int(rectangle[0]):int(rectangle[2])]\n",
    "            crop_img = cv2.resize(crop_img,(160,160))\n",
    "\n",
    "            new_img,_ = utils.Alignment_1(crop_img,landmark)\n",
    "            new_img = np.expand_dims(new_img,0)\n",
    "\n",
    "            face_encoding = utils.calc_128_vec(self.facenet_model,new_img)\n",
    "            face_encodings.append(face_encoding)\n",
    "\n",
    "        face_names = []\n",
    "        for face_encoding in face_encodings:\n",
    "            # 取出一张脸并与数据库中所有的人脸进行对比，计算得分\n",
    "            matches = utils.compare_faces(self.known_face_encodings, face_encoding, tolerance = 0.9)\n",
    "            name = \"Unknown\"\n",
    "            # 找出距离最近的人脸\n",
    "            face_distances = utils.face_distance(self.known_face_encodings, face_encoding)\n",
    "            # 取出这个最近人脸的评分\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                name = self.known_face_names[best_match_index]\n",
    "            face_names.append(name)\n",
    "\n",
    "        rectangles = rectangles[:,0:4]\n",
    "        #-----------------------------------------------#\n",
    "        #   画框~!~\n",
    "        #-----------------------------------------------#\n",
    "        for (left, top, right, bottom), name in zip(rectangles, face_names):\n",
    "            cv2.rectangle(draw, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "            \n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            cv2.putText(draw, name, (left , bottom - 15), font, 0.75, (255, 255, 255), 2) \n",
    "        return draw\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    dududu = face_rec()\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        ret, draw = video_capture.read()\n",
    "        dududu.recognize(draw) \n",
    "        cv2.imshow('Video', draw)\n",
    "        if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
